{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f337c0-c343-414d-9d9d-a37902ba200f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build Machine Learning Pipeline using Lung Disease Detection Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d3adb2-2c1c-4ffc-875d-f819901f6213",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this assignment you will use lung disease detection (use Hernia datasets) use case to build a Machine Learning Pipeline,  ML tasks should consist of at least three stages: data loading/processing, model training, and model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da246581-38fc-48c5-81cd-941faf40a51d",
   "metadata": {},
   "source": [
    "## Resouces\n",
    "- Original ML code is available in `mlops_training_handson_practice/lung_disease_detection/notebooks/lung_disease_detection_workflow_solution.ipynb`\n",
    "- How to build ML pipeline can refer to `mlops_training_handson_practice/flower_classification/notebooks/flower_classification_pipeline.ipynb` \n",
    "- Docker image to provide the dependencies and libraries: `zdou001/only_tests:flower-nightly`\n",
    "- Datasets url:\n",
    "    https://github.com/ZoieD/Hernia_X-ray_images_sample/raw/main/Hernia_sample50.tgz\n",
    "   or https://github.com/ZoieD/Hernia_X-ray_images_sample/raw/main/Hernia_sample20.tgz\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b50f317-ffb4-4978-9d25-e3b0ddff9dc4",
   "metadata": {},
   "source": [
    "## Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4aeca3-9e02-497a-a7a7-8c32a0fe2d9f",
   "metadata": {},
   "source": [
    "### Install Kubeflow pipelines SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef92905-07d9-490e-9912-e4f0ebff4e08",
   "metadata": {},
   "source": [
    " The first step is to install the Kubeflow Pipelines SDK package. Note: you already have all libraries installed in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc2a130-746b-4105-987e-ecc7e8353fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user --upgrade kfp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7056db2d-dc38-40a3-8e01-ddd18aed9967",
   "metadata": {},
   "source": [
    "After the installation, we need to restart kernel for changes to take effect:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334868f9-72cf-42c9-b96f-10e6cb4310cd",
   "metadata": {},
   "source": [
    "Check if the install was successful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae47cd2-e1ad-4345-8661-d22c62ec9434",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which dsl-compile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7807486-9f01-464c-90e9-954352784701",
   "metadata": {},
   "source": [
    "You should see /usr/local/bin/dsl-compile above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1385acbf-bf3b-4f6a-bfb1-1adc27190f24",
   "metadata": {},
   "source": [
    "### Build Container Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd770221-869f-40d1-8ea5-988c8d752b5d",
   "metadata": {},
   "source": [
    "##### Import Kubeflow SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b23c3-b389-44b7-93de-abe4cf50575d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "501a5049-8c19-4d07-b4ff-e71a3698561c",
   "metadata": {},
   "source": [
    "##### Define a fucntion to converts a Python function to a component and returns a task using `kfp.components.func_to_container_op`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb16b0e1-03a2-4373-b612-7d0253a67c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f262b1cf-f56d-497c-89a2-2733eb3d7022",
   "metadata": {},
   "source": [
    "##### Think about what are the ML tasks and create ML pipeline components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507b18b-f369-498e-bded-25c89ed44942",
   "metadata": {},
   "source": [
    "Create standalone python function for ML tasks -task1()  with the input(InputPath)  and output(OutputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cbaff9-7ba4-4c71-996a-460f0bf5c537",
   "metadata": {},
   "outputs": [],
   "source": [
    "@func_to_container_op\n",
    "def xxx_task(\n",
    "    # dataset_url: str,\n",
    "    # data_dir: OutputPath(str)\n",
    "):\n",
    "    \"\"\"Download Hernia X-ray image data\"\"\"\n",
    "    # import libraries\n",
    "    \n",
    "    \n",
    "    # load dataset\n",
    "    \n",
    "    \n",
    "    # print output in logs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05447f8-9d6a-4916-afcd-ff755564f496",
   "metadata": {},
   "source": [
    "Create standalone python function for ML tasks - task2() with the input(InputPath)  and output(OutputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c275dbf9-9734-4be5-b2e6-717edd8b662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@func_to_container_op\n",
    "def xxx_task(\n",
    "    # data_dir: InputPath(str),\n",
    "    # batch_size: int,\n",
    "    # dropout_rate: float,\n",
    "    # learning_rate: float,\n",
    "    # epochs: int,\n",
    "    # model_dir: OutputPath(str)\n",
    "):\n",
    "    # import libraries\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"Split data into train and validation\"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \"\"\"Image Augmentation\"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"Create generators from data frame\"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"Define the model\"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"Train the model\"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # print model summary and list model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668b12e2-fe3b-447d-98e6-abeb281cdba9",
   "metadata": {},
   "source": [
    "Create standalone python function for ML tasks - task3() with the input(InputPath)  and output(OutputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af9d889-a0f9-4ce7-ba87-4fcd8777f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@func_to_container_op\n",
    "def xxx_task(\n",
    "    # data_dir: InputPath(str),\n",
    "    # model_dir: InputPath(str),\n",
    "    # metrics_path: OutputPath(str)\n",
    ") -> NamedTuple(\"EvaluationOutput\", [(\"mlpipeline_metrics\", \"Metrics\")]\n",
    "    ):\n",
    "    \"\"\"Loads a saved model from file and uses a pre-downloaded dataset for evaluation.\n",
    "    Model metrics are persisted to `/mlpipeline-metrics.json` for Kubeflow Pipelines\n",
    "    metadata.\"\"\"\n",
    "    # import libraries\n",
    "\n",
    "\n",
    "    \"\"\"Get Hernia test dataset \"\"\"\n",
    "\n",
    "    \n",
    "    \"\"\"Get val_test_datagen\"\"\"\n",
    "\n",
    "    \n",
    "    \"\"\"Create test generators from data frame\"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \"\"\"Load model and evalutate using metrics\"\"\"\n",
    "\n",
    "    \n",
    "        \n",
    "    # save results to json\n",
    "    metrics_dict = {}\n",
    "    # metrics_dict[\"f1\"] = round(f1, 3)\n",
    "    # metrics_dict[\"accuracy\"] = round(acc, 3)\n",
    "    \n",
    "    with open(metrics_path, 'w') as f:\n",
    "        json.dump(metrics_dict, f)\n",
    "    \n",
    "    out_tuple = namedtuple(\"EvaluationOutput\", [\"mlpipeline_metrics\"])\n",
    "\n",
    "    return out_tuple(json.dumps(metrics_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe15ea01-eab9-406a-9e95-d0ee1805bd34",
   "metadata": {},
   "source": [
    "### Build Kubeflow Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e71d9c5-23ec-420d-a31b-585a93652505",
   "metadata": {},
   "source": [
    "Our next step will be to create the various components that will make up the pipeline. Define the pipeline using the *@dsl.pipeline* decorator.\n",
    "\n",
    "The pipeline function is defined and includes a number of paramters that will be fed into our various components throughout execution. Kubeflow Pipelines are created decalaratively. This means that the code is not run until the pipeline is compiled. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625f8b15-5bca-4a4d-9fea-47973d0834c5",
   "metadata": {},
   "source": [
    "Define the pipeline and define parameters to be fed into pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9655cef9-2bdb-48a8-8c37-8b34f9facf5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4ec10e4-043f-4fd5-bb89-59640272e819",
   "metadata": {},
   "source": [
    "##### Run pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7e615a-18de-4445-837f-7a523fd838e1",
   "metadata": {},
   "source": [
    "Finally we feed our pipeline definition into the compiler and run it as an experiment. This will give us 2 links at the bottom that we can follow to the [Kubeflow Pipelines UI](https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/) where you can check logs, artifacts, inputs/outputs, and visually see the progress of your pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40002434-830a-45a1-abb5-d0d5f6c7d3cc",
   "metadata": {},
   "source": [
    "Create a client to enable communication with the Pipelines API server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2821fb25-2a95-4fc3-98b9-c8e05d18c6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b5a481b-b0e9-47a3-b734-8d4e9b1fb193",
   "metadata": {},
   "source": [
    "Define expeirments, Compile and Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ae0630-52ce-4b95-815f-b64b9785917c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d66f5ed-a923-49a4-9fd9-1a90cf52f77f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c1426-8cf1-4286-a0e6-1669fe742699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5852c-e26b-4bc1-bc4b-2ffc3ca7c6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
